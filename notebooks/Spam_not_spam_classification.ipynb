{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Coursework Part 1: Detecting Spam with Spark\n",
    "\n",
    "### Classifying messages to detect spam. \n",
    "\n",
    "The overall goal is to transform the data into so that we can build a classifier. \n",
    "Then some aspects of the data and it's preparation will be explored. We will \n",
    "specifically study the effect of \n",
    "* the size of training set \n",
    "* the size of the representation vector, and \n",
    "* the preprocessing with stopword removal and/or lemmatisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read some files and prepare a (f,w) RDD \n",
    "Reading the directory with text files from the distributed file system (`hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1`), and loading all text files using wholeTextFiles(), which loads the text per file, i.e. tuples (f,t)\n",
    "\n",
    "Then splitting the text into words (lower case), creating a (file,word) RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hdfs://saltdean.nsqdc.city.ac.uk/data/spam/bare/part1/3-1msg1.txt', 'subject'), ('hdfs://saltdean.nsqdc.city.ac.uk/data/spam/bare/part1/3-1msg1.txt', 're'), ('hdfs://saltdean.nsqdc.city.ac.uk/data/spam/bare/part1/3-1msg1.txt', '2')]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# USE DEPENDING ON DATASTORE\n",
    "#prefix = '/data/tempstore/'\n",
    "prefix = 'hdfs://saltdean.nsqdc.city.ac.uk/data/'\n",
    "\n",
    "dirPath = prefix + 'spam/bare/part1'\n",
    "\n",
    "\n",
    "def read_fw_RDD( argDir ): # package tasks a/b into a function for later use\n",
    "    ### task a) read the files\n",
    "    fwL_RDD = sc.wholeTextFiles(argDir) #loading all text files from the distributed file system dirpath using wholeTextFiles(), which loads the tuples(f,t)\n",
    "    #print('Read {} files from directory {}'.format(3,argDir)) # status message for testing, can be disabled later on\n",
    "    #print('file word count histogram') # the histogram can be useful for checking later \n",
    "    #print(fwL_RDD.map(lambda fwL: (len(fwL[1]))).histogram([0,10,100,1000,10000]))\n",
    "    ### task b) split words\n",
    "    fw_RDD = fwL_RDD.flatMap(splitwords) # inputting the splitwords function defined below as a flatMap argument\n",
    "    return fw_RDD # A fw_RDD should be returned\n",
    "\n",
    "def splitwords(filenamecontent): # function for splitting text into lower case words and creating (file,word) RDD ####\n",
    "    f,c = filenamecontent #### splitting the filenamecontent tuple into separate lists of filename and text content    \n",
    "    word_list = re.split('\\W+',c.lower()) #### create a word list - split the words in text and make them lower case\n",
    "    fw_list = [] #### creating an empty list \n",
    "    for w in word_list: #### looping through every element in the word list\n",
    "        fw_list.append((f,w)) #### creating a (f,w) tuple and adding it to the fw_list\n",
    "    return fw_list ####\n",
    "\n",
    "fw_RDD = read_fw_RDD(dirPath) # for testing\n",
    "#print(fw_RDD.take(3)) # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task c) Normalised word count lists\n",
    "Generating the `[(word,count), ...]` list per file and to create a word frequency vector. Normalising the term frequency (TF) vector by the total word count per file. \n",
    "\n",
    "For normalisation we need to total word count per file. There are a number of ways to do this. You can use a nested list comprehension for this (go through the (w,c) list and divide each c by the sum of all c, which you can get with a list comprehension over all [(w,c),...]). Alternatively, you can write a function where you can create local variables, e.g. for the number of words per file.  Another option is to use a separate RDD with (f,twc), where 'twc' is for total word count, and which you can create from the (f,[(w,c), ... ]) RDD. \n",
    "This new RDD can then be joined with the (f,[(w,c), ... ]) RDD and then the (w,c) list be normalised in a list comprehension. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hdfs://saltdean.nsqdc.city.ac.uk/data/spam/bare/part1/3-550msg1.txt', [('query', 0.045454545454545456), ('anyone', 0.045454545454545456), ('annotext', 0.045454545454545456), ('', 0.045454545454545456), ('thanks', 0.045454545454545456), ('greek', 0.045454545454545456), ('subject', 0.045454545454545456), ('know', 0.045454545454545456), ('classical', 0.045454545454545456), ('michael', 0.045454545454545456), ('internet', 0.045454545454545456), ('dedicated', 0.045454545454545456), ('sikillian', 0.045454545454545456), ('or', 0.09090909090909091), ('does', 0.045454545454545456), ('lists', 0.09090909090909091), ('latin', 0.045454545454545456), ('bitnet', 0.045454545454545456), ('any', 0.045454545454545456), ('to', 0.045454545454545456)])]\n",
      "\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "def reGrpLst(fw_c): # reorganise the tuples\n",
    "    fw,c = fw_c #### splitting the input into file,word tuple and count \n",
    "    f,w = fw #### splitting the file, word tuple into file and word \n",
    "    # Now that we have sepearted the f,w and c terms we can create the (f,[(w,c)]) structure we want \n",
    "    # This gives the [(word, count), ...] list per file and creates a word frequency vector  \n",
    "    return (f,[(w,c)]) \n",
    " \n",
    "def make_f_tfLn_RDD(argDir):  \n",
    "    fw_RDD = read_fw_RDD( argDir ) # call function from task a & b\n",
    "    #<<< read as in the labs \n",
    "    fw_RDD = fw_RDD.map(lambda x: (x,1))  # change (f,w) to ((f,w),1) ####\n",
    "    fw_c_RDD = fw_RDD.reduceByKey(add) # count the words c to give ((f,w),c) ####\n",
    "    f_wcL_RDD = fw_c_RDD.map(reGrpLst) # use function above to convert ((f,w),c) to (f,[(w,c)]) ####\n",
    "    f_wcL_RDD = f_wcL_RDD.reduceByKey(add) # Appy reduce operation to create [(w,c), ... ,(w,c)] lists per file ####\n",
    "    #<<< Normalising the term frequency  (TF) vector by the total word count per file\n",
    "    f_wcLn_RDD = f_wcL_RDD.map(lambda x: (x[0],[(w, c/sum([c for (w,c) in x[1]])) for (w,c) in x[1]])) ####\n",
    "    return f_wcLn_RDD\n",
    "\n",
    "f_wcLn_RDD = make_f_tfLn_RDD( prefix + 'spam/bare/part1') # for testing\n",
    "#print(f_wcLn_RDD.take(1)) # for testing\n",
    "wcLn = f_wcLn_RDD.take(1)[0][1] # get the first normalised word count list\n",
    "#print('')\n",
    "#print(sum([cn for (w,cn) in wcLn])) # the sum of normalised counts should be close to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task d) Creating hashed feature vectors \n",
    "Use the hashing trick to create fixed size TF vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909090909091, 0.09090909090909091, 0, 0.09090909090909091, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0, 0, 0, 0, 0.045454545454545456, 0, 0, 0.045454545454545456, 0, 0.045454545454545456, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0, 0.045454545454545456, 0.045454545454545456, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0.045454545454545456, 0, 0, 0, 0, 0.09090909090909091, 0.045454545454545456, 0, 0, 0.045454545454545456]\n",
      "\n",
      "0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "def hashing_vectorizer(word_count_list, N): \n",
    "    # use the code from the lecture\n",
    "    v = [0] * N  # create fixed size vector of 0s ####\n",
    "    for word_count in word_count_list:  ####\n",
    "        word,count = word_count # unpack tuple ####\n",
    "        h = hash(word) # get hash value ####\n",
    "        v[h % N] = v[h % N] + count # add count ####\n",
    "    return v # return hashed word vector ####\n",
    "\n",
    "def make_f_wVn_RDD(f_wcLn_RDD, argN):\n",
    "    # apply hashing_vectorizer in a lambda, this is only a one-liner\n",
    "    f_wVec_RDD = f_wcLn_RDD.map(lambda f_wc: (f_wc[0],hashing_vectorizer(f_wc[1],argN)))# apply hashing_vectorizer ####\n",
    "    return f_wVec_RDD ####\n",
    "    \n",
    "N=100\n",
    "f_wVn_RDD = make_f_wVn_RDD(make_f_tfLn_RDD(dirPath),N) # for testing\n",
    "#print(f_wVn_RDD.take(1)[0][1]) # for testing\n",
    "#print('')\n",
    "#print( sum(f_wVn_RDD.take(1)[0][1])) # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task e) Create Labeled Points\n",
    "\n",
    "Determining whether the file is spam (i.e. the filename contains ’spmsg’) and replace the filename by a 1 (spam) or 0 (ham) accordingly. Use map() to create an RDD of LabeledPoint objects. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, [0.0909090909091,0.0909090909091,0.0,0.0909090909091,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0454545454545,0.0,0.0454545454545,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0454545454545,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0454545454545,0.0,0.0,0.0,0.0,0.0909090909091,0.0454545454545,0.0,0.0,0.0454545454545])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def make_lp_RDD(f_tfLn_RDD,argN):\n",
    "    #<<< make a vector\n",
    "    f_wVec_RDD = f_tfLn_RDD.map(lambda f_wc:(f_wc[0],hashing_vectorizer(f_wc[1],argN)))# apply hashing_vectorizer ####\n",
    "    #Detecting spam by filename and transforming into LabeledPoint objects\n",
    "    ## The code below replaces the filename by a 1 (if it is spam) or 0 (if not spam) accordingly. \n",
    "    ## I have used the LabeledPoint function in map() to create a tuple of labeled points ####\n",
    "    ## For the first argument of LabeledPoint, use re.search() to search for 'spmsg' in the filename (x[0]) and set the filename to 0 if it is true and 1 if not\n",
    "    ## The second argument of LabeledPoint is the hash vector x[1]\n",
    "    lp_RDD = f_wVec_RDD.map(lambda x:LabeledPoint(0 if (re.search('spmsg', x[0])) is None else 1,(x[1])))\n",
    "    return lp_RDD\n",
    "\n",
    "lp_RDD = make_lp_RDD(make_f_tfLn_RDD(prefix + 'spam/bare/part1'),100)\n",
    "#print(lp_RDD.take(1)) #for testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task f) Train a classifier \n",
    "\n",
    "Use the `LabeledPoint` objects to train the `LogisticRegression` and calculate the accuracy of the model on the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Logistic Regression\n",
      "training data items: 289, correct: 289\n",
      "training accuracy 100.0%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, NaiveBayes\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "path = prefix + 'spam/stop/part1'\n",
    "\n",
    "N=100\n",
    "def trainModel(f_wcL_RDD,N):\n",
    "    #<<< get the training data as LabeledPoint objects.\n",
    "    trainData = make_lp_RDD(f_wcLn_RDD, N) ## use the make_lp_RDD function defined in the previous section \n",
    "    model = LogisticRegressionWithLBFGS.train(trainData) #### train model on training set \n",
    "    print('training Logistic Regression') \n",
    "    count = trainData.count() # total size of training set \n",
    "    # use model to calculate correctly classified data points####\n",
    "    correct = trainData.map(lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum() \n",
    "    print('training data items: {}, correct: {}'.format(trainData.count(), correct)) # output raw numbers\n",
    "    accuracy = (correct/count) # define accuracy as the ratio of correctly classified points as total count \n",
    "    print('training accuracy {:.1%}'.format(accuracy)) # print accuracy\n",
    "    return model \n",
    "\n",
    "f_wcLn_RDD = make_f_tfLn_RDD(path) # for testing\n",
    "model = trainModel(f_wcLn_RDD,N) # for testing\n",
    "\n",
    "## The code above trains a logistic regression model on the entire training set.\n",
    "## The model is evaluated on the same training set and generates a 100% accuracy as expected due to overfitting. \n",
    "## A better approach would be to use cross validation by splitting the dataset into a set of folds which are used \n",
    "## as separate training and test datasets. Using 10 folds will generate 10 (training, test) dataset pairs, \n",
    "## each of which uses 9/10 of the data for training and 1/10 for testing. The accuracy is computed by calculating \n",
    "##the average after fitting the estimator on the 10 different (training, test) dataset pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task g) Test the classifier\n",
    "\n",
    "Using a different bunch of files from and preparing them like in task~a)-e) before. Then using the trained model to predict the label for each vector you have and compare it to the original to test the performance of your classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using trained logistic regression model in f) to predict labels\n",
      "test data items: 291, correct:219\n",
      "testing accuracy 75.8%\n"
     ]
    }
   ],
   "source": [
    "def testModel(model,f_wcL_RDD,N):\n",
    "    #<<< like with trainModel, transform the data and evaluate it.\n",
    "    testData = make_lp_RDD(f_wcL_RDD, N) #### use the make_lp_RDD function defined earlier to generate a test RDD \n",
    "    print('Using trained logistic regression model in f) to predict labels') \n",
    "    # calculate correctly classified data points ###\n",
    "    correct = testData.map(lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum() \n",
    "    accuracy = (correct/lp_RDD.count()) # define accuracy ### \n",
    "    print('test data items: {}, correct:{}'.format(testData.count(),correct))\n",
    "    print('testing accuracy {:.1%}'.format(accuracy))\n",
    "\n",
    "N = 100 \n",
    "testModel(model,make_f_tfLn_RDD('hdfs://saltdean/data/spam/stop/part10'),N) # for testing\n",
    "\n",
    "\n",
    "## Created a test RDD from .../data/extra/spam/bare/part10 and uses the trained model in f) \n",
    "## to predict the label for each vector. This is compared to the actual labeled values to \n",
    "## calculate the accuracy and test the performance of the classifier. This model achieves \n",
    "## an accuracy of 75.8% which is much lower than the training accuracy calculated above. \n",
    "## The test accuracy would have been improved if cross validation was used to train the model\n",
    "## This would have trained a model which would generalise well and produce a better test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task h) Run experiments \n",
    "\n",
    "Package the whole classifier training and evaluation in one function. Then apply it to the files from different hdfs paths  `/data/extra/spam/lemm`, `/data/extra/spam/stop` and `/data/extra/spam/lemm_stop` in addition to `/data/extra/spam/bare`  and evaluate the accuracy of your classifier. \n",
    "Evaluating the use of larger training sets and the effect of different vector sizes.\n",
    "The combination of the part1-part9 datasets can be achieved by using 'glob' patterns in the filename ('part[1-9]'). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 1: Testing different training set sizes\n",
      "Path = hdfs://saltdean/data/spam/bare/part[1-{}], N = 100\n",
      "=== add part 1\n",
      "hdfs://saltdean/data/spam/bare/part[1-1]\n",
      "training data items: 289, correct: 289\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:254\n",
      "test accuracy 87.3%\n",
      "=== add part 2\n",
      "hdfs://saltdean/data/spam/bare/part[1-2]\n",
      "training data items: 578, correct: 578\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:266\n",
      "test accuracy 91.4%\n",
      "=== add part 3\n",
      "hdfs://saltdean/data/spam/bare/part[1-3]\n",
      "training data items: 867, correct: 867\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:265\n",
      "test accuracy 91.1%\n",
      "=== add part 4\n",
      "hdfs://saltdean/data/spam/bare/part[1-4]\n",
      "training data items: 1156, correct: 1156\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:265\n",
      "test accuracy 91.1%\n",
      "=== add part 5\n",
      "hdfs://saltdean/data/spam/bare/part[1-5]\n",
      "training data items: 1446, correct: 1446\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:264\n",
      "test accuracy 90.7%\n",
      "=== add part 6\n",
      "hdfs://saltdean/data/spam/bare/part[1-6]\n",
      "training data items: 1735, correct: 1708\n",
      "training accuracy 98.4%\n",
      "test data items: 291, correct:274\n",
      "test accuracy 94.2%\n",
      "=== add part 7\n",
      "hdfs://saltdean/data/spam/bare/part[1-7]\n",
      "training data items: 2024, correct: 1990\n",
      "training accuracy 98.3%\n",
      "test data items: 291, correct:280\n",
      "test accuracy 96.2%\n",
      "=== add part 8\n",
      "hdfs://saltdean/data/spam/bare/part[1-8]\n",
      "training data items: 2313, correct: 2258\n",
      "training accuracy 97.6%\n",
      "test data items: 291, correct:275\n",
      "test accuracy 94.5%\n",
      "=== add part 9\n",
      "hdfs://saltdean/data/spam/bare/part[1-9]\n",
      "training data items: 2602, correct: 2540\n",
      "training accuracy 97.6%\n",
      "test data items: 291, correct:276\n",
      "test accuracy 94.8%\n",
      "\n",
      "\n",
      "EXPERIMENT 2: Testing different vector sizes\n",
      "=== N =  3\n",
      "training data items: 2602, correct: 2165\n",
      "training accuracy 83.2%\n",
      "test data items: 291, correct:233\n",
      "test accuracy 80.1%\n",
      "=== N =  10\n",
      "training data items: 2602, correct: 2194\n",
      "training accuracy 84.3%\n",
      "test data items: 291, correct:248\n",
      "test accuracy 85.2%\n",
      "=== N =  30\n",
      "training data items: 2602, correct: 2354\n",
      "training accuracy 90.5%\n",
      "test data items: 291, correct:255\n",
      "test accuracy 87.6%\n",
      "=== N =  100\n",
      "training data items: 2602, correct: 2540\n",
      "training accuracy 97.6%\n",
      "test data items: 291, correct:276\n",
      "test accuracy 94.8%\n",
      "=== N =  300\n",
      "training data items: 2602, correct: 2602\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:284\n",
      "test accuracy 97.6%\n",
      "=== N =  1000\n",
      "training data items: 2602, correct: 2602\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:287\n",
      "test accuracy 98.6%\n",
      "=== N =  3000\n",
      "training data items: 2602, correct: 2602\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:288\n",
      "test accuracy 99.0%\n",
      "=== N =  10000\n",
      "training data items: 2602, correct: 2602\n",
      "training accuracy 100.0%\n",
      "test data items: 291, correct:284\n",
      "test accuracy 97.6%\n",
      "\n",
      "EXPERIMENT 3: Testing differently preprocessed data sets\n",
      "training on parts 1-9, N = 100\n",
      "===  Stopwords removed\n",
      "training data items: 2602, correct: 2425\n",
      "training accuracy 93.2%\n",
      "test data items: 291, correct:251\n",
      "test accuracy 86.3%\n",
      "===  Lemmatised\n",
      "training data items: 2602, correct: 2541\n",
      "training accuracy 97.7%\n",
      "test data items: 291, correct:274\n",
      "test accuracy 94.2%\n",
      "===  No preprocessing\n",
      "training data items: 2602, correct: 2540\n",
      "training accuracy 97.6%\n",
      "test data items: 291, correct:276\n",
      "test accuracy 94.8%\n",
      "===  Lemmatised and stopwords removed\n",
      "training data items: 2602, correct: 2420\n",
      "training accuracy 93.0%\n",
      "test data items: 291, correct:255\n",
      "test accuracy 87.6%\n",
      "\n",
      "====== Done ======\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Please see additional comments for the results of each experiment in the text box below \n",
    "\n",
    "# this function combines tasks f) and g)\n",
    "def trainTestModel(train_RDD,test_RDD,N):\n",
    "    #<<< just combine training and testing here  \n",
    "    model = LogisticRegressionWithLBFGS.train(train_RDD)  # training the Logistic Regression model\n",
    "    ## The trained Logistic Regression is evaluated on the training dataset to compute the training accuracy \n",
    "    correct = train_RDD.map(lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum()\n",
    "    count = train_RDD.count() # total size of training set \n",
    "    print('training data items: {}, correct: {}'.format(count, correct))\n",
    "    accuracy = (correct/count) # define accuracy \n",
    "    print('training accuracy {:.1%}'.format(accuracy)) # and print training accuracy \n",
    "    ## Using the trained Logistic Regression model above to test on the test RDD (unseen data)\n",
    "    ## This is used to calculate the test accuracy \n",
    "    correct = test_RDD.map( lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum()\n",
    "    count = test_RDD.count() ## total size of test set \n",
    "    print('test data items: {}, correct:{}'.format(count,correct))\n",
    "    accuracy = (correct/count) # computes test accuracy  ### \n",
    "    print('test accuracy {:.1%}'.format(accuracy)) ## prints the test accuracy \n",
    "    \n",
    "    return model\n",
    "\n",
    "#trainTestModel(train_RDD,test_RDD,100)\n",
    "#print()\n",
    "    \n",
    "# prepare the part directories and the path\n",
    "dirPattern = 'hdfs://saltdean/data/spam/bare/part[1-{}]' # the {} can be filled by 'dirPattern.format(i)' \n",
    "# create the path for the test set\n",
    "testPath = 'hdfs://saltdean/data/spam/bare/part10'\n",
    "\n",
    "print('EXPERIMENT 1: Testing different training set sizes')\n",
    "print('Path = {}, N = {}'.format(dirPattern,N)) # using format to make sure we record the parameters of the experiment\n",
    "#<<< make the test set, it will be constant for this experiment\n",
    "#<<< loop over i the number of parts for training (1-9)\n",
    "f_wcLn_RDD = make_f_tfLn_RDD(testPath)\n",
    "test_RDD = make_lp_RDD(f_wcLn_RDD, N) #<<< make the test set, it will be constant for this experiment\n",
    "for i in range(1,10):   #loop over i the number of parts for training (1-9)\n",
    "    print('=== add part',i)\n",
    "    trainPath = dirPattern.format(i) # in the loop you can create a path like this\n",
    "    print(trainPath) #just for testing, remove later\n",
    "    #<<< create the trainRDD (using the make_f_tfLn_RDD and make_lp_RDD methods)\n",
    "    f_wcLn_RDD = make_f_tfLn_RDD(trainPath)\n",
    "    train_RDD = make_lp_RDD(f_wcLn_RDD, N)\n",
    "    # calling the trainTestModel function and passing train_RDD (this will vary in size at each iteration), test_RDD and N value as inputs \n",
    "    trainTestModel(train_RDD,test_RDD,N)\n",
    "\n",
    "print('')\n",
    "    \n",
    "print('\\nEXPERIMENT 2: Testing different vector sizes')\n",
    "#<<< loop over different values for N. 3,10,30,100,300, ... is a good pattern\n",
    "for N in [3,10,30,100,300,1000,3000,10000]:\n",
    "    print('=== N = ',N)\n",
    "    i = 9;\n",
    "    trainPath = dirPattern.format(i)\n",
    "    #<<< create the train and test RDD (using your make_f_tfLn_RDD method and make_lp_RDD)\n",
    "    f_wcLn_RDD = make_f_tfLn_RDD(trainPath)\n",
    "    train_RDD = make_lp_RDD(f_wcLn_RDD, N)\n",
    "    f_wcLn_RDD = make_f_tfLn_RDD(testPath)\n",
    "    test_RDD = make_lp_RDD(f_wcLn_RDD, N)\n",
    "    # calling the trainTestModel function and passing train_RDD, test_RDD and various N values as inputs \n",
    "    trainTestModel(train_RDD,test_RDD,N)  \n",
    "\n",
    "N = 100 # change to what you feel is a good compromise between computation and accuracy\n",
    "# the dictionary below helps associate description and paths.\n",
    "setDict = {'No preprocessing': prefix + 'spam/bare/',\n",
    "           'Stopwords removed': prefix + 'spam/stop/',\n",
    "           'Lemmatised': prefix + 'spam/lemm/',\n",
    "           'Lemmatised and stopwords removed': prefix + 'spam/lemm_stop/'}\n",
    "\n",
    "print('\\nEXPERIMENT 3: Testing differently preprocessed data sets')\n",
    "print('training on parts 1-9, N = {}'.format(N))\n",
    "for sp in setDict:\n",
    "    print('=== ',sp)\n",
    "    #<<< make the training data (part1-9) and test data (part10) RDDs and evaluate \n",
    "    trainPath = setDict[sp] + 'part[1-9]'    \n",
    "    testPath = setDict[sp] + 'part10' \n",
    "    # Like in experiments 1 and 2,  creating the trainR and test RDD (using make_f_tfLn_RDD and make_lp_RDD)\n",
    "    f_wcLn_RDD = make_f_tfLn_RDD(trainPath)\n",
    "    train_RDD = make_lp_RDD(f_wcLn_RDD, N)\n",
    "    f_wcLn_RDD = make_f_tfLn_RDD(testPath)\n",
    "    test_RDD = make_lp_RDD(f_wcLn_RDD, N)\n",
    "     # calling the trainTestModel function and passing the relevant arguments \n",
    "    trainTestModel(train_RDD,test_RDD,N)\n",
    "\n",
    "print('\\n====== Done ======')\n",
    "\n",
    " \n",
    "## Comments on results for experiments 1,2 and 3. Also, includes comments on lemmatisation, stop word removal on classification accuracy.\n",
    "\n",
    "## Experiment 1 - As training set size increases, we see that the training accuracy decreases from 100% to 93% and test accuracy \n",
    "##increases from 76% to a maximum of 89.3% (when training with parts 1-8). This is expected as increasing training set \n",
    "##size reduces overfitting and hence we see the training accuracy decreasing. On the contrary, test accuracy increases \n",
    "##because the trained model is able to generalise better. We see that the test accuracy reaches a maximum of 96.2% when \n",
    "##combining parts 1-7 for training and parts 8-10 for testing (70/30 train:test ratio) and then decreases slightly when \n",
    "##using a 80/20 or 90/10 train:test split. The reason for this could be because there are less enough samples in the test dataset \n",
    "#with the 90/10 split which could lower the classification accuracy slightly. \n",
    "##Note: Re running the experiment again seems to produce slight changes in accuracy results. This may due to the hashing function \n",
    "##producing random collisions.\n",
    "\n",
    "##Experiment 2 - Hashing maps each word onto a position in a vector. Increasing the vector size increases accuracy because dataset \n",
    "#is compressed less. As vector size is increased, likelihood of collisions is less and less information is loss in the hashing process.\n",
    "\n",
    "##Experiment 3 - Effect of lemmatisation seems to have a similar accuracy to no preprocessing (94.2% and 94.8% respectively). \n",
    "##Lemmatisation reduces words down to their base form so that different words with the same base are not treated separately \n",
    "##(and sepearate frequencies are not calculated). Stop word removal removes common stop words like 'and', 'the', 'a', 'of' which occur \n",
    "##frequently in all documents and do not contribute much to classification accuracy. Effect of stop word removal results in lose of\n",
    "##information and reduced accuracy (86.3%), the effect of which is more pronounced compared to lemmatisation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comments on results for experiments 1,2 and 3. Also, includes comments on lemmatisation, stop word removal on classification accuracy.\n",
    "\n",
    "Experiment 1 - As training set size increases, we see that the training accuracy decreases from 100% to 93% and test accuracy increases from 76% to a maximum of 89.3% (when training with parts 1-8). This is expected as increasing training set size reduces overfitting and hence we see the training accuracy decreasing. On the contrary, test accuracy increases because the trained model is able to generalise better.\n",
    "We see that the test accuracy reaches a maximum of 96.2% when combining parts 1-7 for training and parts 8-10 for testing (70/30 train:test ratio) and then decreases slightly when using a 80/20 or 90/10 train:test split. The reason for this could be because there are less enough samples in the test data set with the 90/10 split which could lower the classification accuracy slightly. \n",
    "\n",
    "Note: Re running the experiment again seems to produce slight changes in accuracy results. This may due to the hashing function producing random collisions.\n",
    "\n",
    "Experiment 2 - Hashing maps each word onto a position in a vector. Increasing the vector size increases accuracy because data set is compressed less. As vector size is increased, likelihood of collisions is less and less information is loss in the hashing process.    \n",
    "\n",
    "Experiment 3 - Effect of lemmatisation seems to have a similar accuracy to no preprocessing (94.2% and 94.8% respectively). Lemmatisation reduces words down to their base form so that different words with the same base are not treated separately (and sepearate frequencies are not calculated). Stop word removal removes common stop words like 'and', 'the', 'a', 'of' which occur  frequently in all documents and do not contribute much to classification accuracy. Effect of stop word removal results in lose of information and reduced accuracy (86.3%), the effect of which is more pronounced compared to lemmatisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Appendix\n",
    "This code is just needed if there is an error message \"sc undefined\", when starting the script. In that case the code below should be run first. All code cells from the beginning has to be run again, as the new context has no information about what happened before.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped existing SparkContext\n",
      "Created new SparkContext\n",
      "Proterties of sc:  [('spark.eventLog.enabled', 'true'), ('spark.executor.logs.rolling.time.interval', 'daily'), ('spark.executor.extraJavaOptions', '-Xss8192k'), ('spark.master', 'spark://10.207.1.85:7077'), ('spark.driver.port', '34450'), ('spark.executor.id', 'driver'), ('spark.executor.logs.rolling.strategy', 'time'), ('spark.driver.memory', '1g'), ('spark.app.id', 'app-20170313040910-0836'), ('spark.executor.memory', '1g'), ('spark.rdd.compress', 'True'), ('spark.driver.host', '10.207.1.85'), ('spark.app.name', 'Coursework part 1'), ('spark.cores.max', '2'), ('spark.serializer.objectStreamReset', '100'), ('spark.submit.deployMode', 'client'), ('spark.driver.extraJavaOptions', '-Xss8192k'), ('spark.eventLog.dir', '/data/sparklog')]\n"
     ]
    }
   ],
   "source": [
    "# try this in case of \"sc undefined\" errors\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "try: \n",
    "    sc.stop()\n",
    "    print('Stopped existing SparkContext')\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "\n",
    "try: \n",
    "    sc = SparkContext(appName='Coursework part 1')\n",
    "    print('Created new SparkContext')\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "print('Proterties of sc: ',list(sc.getConf().getAll()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
